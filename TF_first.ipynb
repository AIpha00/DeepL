{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个5*3的矩阵\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5587, 0.6011, 0.1607],\n",
      "        [0.0135, 0.0260, 0.5441],\n",
      "        [0.3917, 0.8434, 0.0431],\n",
      "        [0.7827, 0.1167, 0.1080],\n",
      "        [0.9713, 0.1819, 0.2145]])\n"
     ]
    }
   ],
   "source": [
    "##随机初始化一个矩阵\n",
    "x_random = torch.rand(5,3)\n",
    "print(x_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个0填充的矩阵，数据类型为long\n",
    "x_long = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "##创建tensor(张量矩阵)\n",
    "x_tensor = torch.tensor([5.5, 3])\n",
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2548, -0.0500, -0.9239],\n",
      "        [ 0.9588, -0.9675,  0.4927],\n",
      "        [-0.5409, -0.5524,  1.8144],\n",
      "        [-0.5791, -1.6736, -0.2182],\n",
      "        [ 0.4325,  2.5892, -0.2272]])\n"
     ]
    }
   ],
   "source": [
    "##根据现有的张量(维度和数量)创建新的张量(维度和数量相同)。\n",
    "x = x_tensor.new_ones(5,3, dtype=torch.double)  ##创建一个新对象，在之前的张量上(继承了这个对象)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float) ##继承tensor的size\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      "\n",
      "tensor([[0.0612],\n",
      "        [0.5827],\n",
      "        [0.1419],\n",
      "        [0.4089],\n",
      "        [0.9934]])\n",
      "x+y:\n",
      "\n",
      "tensor([[ 0.3160,  0.0113, -0.8627],\n",
      "        [ 1.5415, -0.3848,  1.0754],\n",
      "        [-0.3990, -0.4105,  1.9563],\n",
      "        [-0.1703, -1.2648,  0.1906],\n",
      "        [ 1.4259,  3.5826,  0.7662]])\n"
     ]
    }
   ],
   "source": [
    "##各种操作语法\n",
    "y = torch.rand(5,1)   ###同样存在广播\n",
    "print('y:\\n')\n",
    "print(y)\n",
    "\n",
    "print('x+y:\\n')\n",
    "print(x + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3160,  0.0113, -0.8627],\n",
       "        [ 1.5415, -0.3848,  1.0754],\n",
       "        [-0.3990, -0.4105,  1.9563],\n",
       "        [-0.1703, -1.2648,  0.1906],\n",
       "        [ 1.4259,  3.5826,  0.7662]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1382, -1.4314, -1.7900],\n",
      "        [-0.4879, -0.4154,  1.6822],\n",
      "        [-0.9179,  0.1184,  2.2554],\n",
      "        [ 1.0950, -0.7271,  0.0160],\n",
      "        [ 0.5137,  2.9146,  0.0053]])\n"
     ]
    }
   ],
   "source": [
    "###任何以‘_’结尾的操作都会用结果替换原变量，我(吕松科)觉得不好！！\n",
    "y = torch.randn(5,3)\n",
    "y_ = y.view(15)\n",
    "y_ = y_.view(5,3)\n",
    "y_.add_(x)\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不存在cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('存在 cuda')\n",
    "else:\n",
    "    print('不存在cuda')\n",
    "#     device = torch.device('cuda')\n",
    "#     y = torch.ones_like(x, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "###自动计算梯度，进行反向传播算法(bp)\n",
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y ** 2 * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,1,1], requires_grad=True, dtype=torch.float)\n",
    "\n",
    "y = x * 2\n",
    "# while y.data.norm() < 1000:\n",
    "#     y = y*2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1773.6200)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000e-01, 2.0000e+00, 2.0000e-04])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)  ##传入的梯度时的x值\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3538,  1.0040, -0.7025], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
